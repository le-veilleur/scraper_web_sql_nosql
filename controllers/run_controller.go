package controllers

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"sync"
	"time"

	"github.com/gofiber/fiber/v2"
	"github.com/maxime-louis14/api-golang/logger"
)

// LaunchScraper lance le scraper via une route API
func LaunchScraper(c *fiber.Ctx) error {
	start := time.Now()
	requestID := c.Locals("requestID").(string)

	logger.LogInfo("D√©marrage du scraper", map[string]interface{}{
		"request_id": requestID,
	})

	// Ajoute un d√©lai de 4 secondes
	time.Sleep(4 * time.Second)

	// Ex√©cute le scraper
	if err := RunScraper(); err != nil {
		logger.LogError("Erreur lors de l'ex√©cution du scraper", err, map[string]interface{}{
			"request_id": requestID,
		})
		return c.Status(500).SendString("Erreur lors de l'ex√©cution du scraper")
	}

	duration := time.Since(start)
	logger.LogInfo("Scraper ex√©cut√© avec succ√®s", map[string]interface{}{
		"request_id": requestID,
		"duration":   duration.String(),
	})

	return c.Status(200).SendString("Scraper ex√©cut√© avec succ√®s")
}

// RunScraper ex√©cute le binaire du scraper
func RunScraper() error {
	start := time.Now()
	// Chemin vers le binaire du scraper
	scraperPath := "/app/scraper"

	logger.LogInfo("V√©rification de l'existence du binaire scraper", map[string]interface{}{
		"scraper_path": scraperPath,
	})

	// V√©rifie que le fichier existe
	if _, err := os.Stat(scraperPath); os.IsNotExist(err) {
		logger.LogError("Binaire scraper introuvable", err, map[string]interface{}{
			"scraper_path": scraperPath,
		})
		return err
	}

	logger.LogInfo("Lancement du binaire scraper", map[string]interface{}{
		"scraper_path": scraperPath,
	})

	// S'assurer que le r√©pertoire de sauvegarde existe
	dataDir := "/go_api_mongo_scrapper/scraper"
	if err := os.MkdirAll(dataDir, 0755); err != nil {
		logger.LogError("Erreur lors de la cr√©ation du r√©pertoire de sauvegarde", err, map[string]interface{}{
			"data_dir": dataDir,
		})
		// Continuer quand m√™me, le volume peut d√©j√† exister
	}

	// Commande pour ex√©cuter le scraper
	cmd := exec.Command(scraperPath)

	// D√©finir le r√©pertoire de travail pour que le fichier data.json soit sauvegard√© dans un emplacement connu
	cmd.Dir = dataDir

	// Associe les sorties standard et erreur du scraper aux sorties du serveur
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr

	// Ex√©cute la commande
	if err := cmd.Run(); err != nil {
		logger.LogError("√âchec de l'ex√©cution du scraper", err, map[string]interface{}{
			"scraper_path": scraperPath,
		})
		return err
	}

	duration := time.Since(start)
	logger.LogInfo("Scraper ex√©cut√© avec succ√®s", map[string]interface{}{
		"scraper_path": scraperPath,
		"duration":     duration.String(),
	})
	return nil
}

// LogMessage repr√©sente un message de log pour le streaming
type LogMessage struct {
	Type      string `json:"type"`      // "stdout", "stderr", "info", "error", "done"
	Message   string `json:"message"`   // Contenu du message
	Timestamp string `json:"timestamp"` // Timestamp ISO 8601
}

// LaunchScraperStream lance le scraper et stream les logs en temps r√©el via SSE
func LaunchScraperStream(c *fiber.Ctx) error {
	requestID := c.Locals("requestID").(string)
	start := time.Now()

	// Configuration des headers pour Server-Sent Events (SSE)
	c.Set("Content-Type", "text/event-stream")
	c.Set("Cache-Control", "no-cache")
	c.Set("Connection", "keep-alive")
	c.Set("X-Accel-Buffering", "no") // D√©sactive le buffering de nginx

	logger.LogInfo("D√©marrage du scraper (mode streaming)", map[string]interface{}{
		"request_id": requestID,
	})

	// Chemin vers le binaire du scraper
	scraperPath := "/app/scraper"

	// V√©rifie que le fichier existe
	if _, err := os.Stat(scraperPath); os.IsNotExist(err) {
		errorMsg := fmt.Sprintf("‚ùå Binaire scraper introuvable: %s", scraperPath)
		logger.LogError("Binaire scraper introuvable", err, map[string]interface{}{
			"scraper_path": scraperPath,
			"request_id":   requestID,
		})
		return c.Status(500).SendString(errorMsg)
	}

	// Utiliser directement BodyWriter pour le streaming
	w := c.Context().Response.BodyWriter()

	// Message de d√©marrage
	startMsg := LogMessage{
		Type:      "info",
		Message:   "üöÄ D√©marrage du scraper...",
		Timestamp: time.Now().Format(time.RFC3339),
	}
	jsonData, _ := json.Marshal(startMsg)
	fmt.Fprintf(w, "data: %s\n\n", jsonData)

	// S'assurer que le r√©pertoire de sauvegarde existe
	dataDir := "/go_api_mongo_scrapper/scraper"
	if err := os.MkdirAll(dataDir, 0755); err != nil {
		logger.LogError("Erreur lors de la cr√©ation du r√©pertoire de sauvegarde", err, map[string]interface{}{
			"data_dir":   dataDir,
			"request_id": requestID,
		})
		// Continuer quand m√™me, le volume peut d√©j√† exister
	}

	// Commande pour ex√©cuter le scraper
	cmd := exec.Command(scraperPath)

	// D√©finir le r√©pertoire de travail pour que le fichier data.json soit sauvegard√© dans un emplacement connu
	cmd.Dir = dataDir

	// Cr√©er des pipes pour capturer stdout et stderr
	stdoutPipe, err := cmd.StdoutPipe()
	if err != nil {
		errorMsg := fmt.Sprintf("‚ùå Erreur lors de la cr√©ation du pipe stdout: %v", err)
		msg := LogMessage{
			Type:      "error",
			Message:   errorMsg,
			Timestamp: time.Now().Format(time.RFC3339),
		}
		jsonData, _ := json.Marshal(msg)
		fmt.Fprintf(w, "data: %s\n\n", jsonData)
		return err
	}

	stderrPipe, err := cmd.StderrPipe()
	if err != nil {
		errorMsg := fmt.Sprintf("‚ùå Erreur lors de la cr√©ation du pipe stderr: %v", err)
		msg := LogMessage{
			Type:      "error",
			Message:   errorMsg,
			Timestamp: time.Now().Format(time.RFC3339),
		}
		jsonData, _ := json.Marshal(msg)
		fmt.Fprintf(w, "data: %s\n\n", jsonData)
		return err
	}

	// D√©marrer la commande
	if err := cmd.Start(); err != nil {
		errorMsg := fmt.Sprintf("‚ùå Erreur lors du d√©marrage du scraper: %v", err)
		msg := LogMessage{
			Type:      "error",
			Message:   errorMsg,
			Timestamp: time.Now().Format(time.RFC3339),
		}
		jsonData, _ := json.Marshal(msg)
		fmt.Fprintf(w, "data: %s\n\n", jsonData)
		logger.LogError("Erreur lors du d√©marrage du scraper", err, map[string]interface{}{
			"request_id": requestID,
		})
		return err
	}

	// WaitGroup pour synchroniser les goroutines
	var wg sync.WaitGroup

	// Goroutine pour lire stdout ligne par ligne
	wg.Add(1)
	go func() {
		defer wg.Done()
		scanner := bufio.NewScanner(stdoutPipe)
		for scanner.Scan() {
			line := scanner.Text()
			msg := LogMessage{
				Type:      "stdout",
				Message:   line,
				Timestamp: time.Now().Format(time.RFC3339),
			}
			jsonData, _ := json.Marshal(msg)
			fmt.Fprintf(w, "data: %s\n\n", jsonData)
		}
	}()

	// Goroutine pour lire stderr ligne par ligne
	wg.Add(1)
	go func() {
		defer wg.Done()
		scanner := bufio.NewScanner(stderrPipe)
		for scanner.Scan() {
			line := scanner.Text()
			msg := LogMessage{
				Type:      "stderr",
				Message:   line,
				Timestamp: time.Now().Format(time.RFC3339),
			}
			jsonData, _ := json.Marshal(msg)
			fmt.Fprintf(w, "data: %s\n\n", jsonData)
		}
	}()

	// Attendre la fin de l'ex√©cution
	err = cmd.Wait()
	wg.Wait() // Attendre que toutes les goroutines de lecture soient termin√©es

	if err != nil {
		errorMsg := fmt.Sprintf("‚ùå Le scraper s'est termin√© avec une erreur: %v", err)
		msg := LogMessage{
			Type:      "error",
			Message:   errorMsg,
			Timestamp: time.Now().Format(time.RFC3339),
		}
		jsonData, _ := json.Marshal(msg)
		fmt.Fprintf(w, "data: %s\n\n", jsonData)
		logger.LogError("√âchec de l'ex√©cution du scraper", err, map[string]interface{}{
			"scraper_path": scraperPath,
			"request_id":   requestID,
		})
		return err
	}

	// Message de fin
	duration := time.Since(start)
	successMsg := fmt.Sprintf("‚úÖ Scraper ex√©cut√© avec succ√®s en %s", duration.String())
	msg := LogMessage{
		Type:      "done",
		Message:   successMsg,
		Timestamp: time.Now().Format(time.RFC3339),
	}
	jsonData, _ = json.Marshal(msg)
	fmt.Fprintf(w, "data: %s\n\n", jsonData)

	logger.LogInfo("Scraper ex√©cut√© avec succ√®s (mode streaming)", map[string]interface{}{
		"request_id": requestID,
		"duration":   duration.String(),
	})

	return nil
}

// GetScraperData r√©cup√®re le fichier JSON g√©n√©r√© par le scraper
func GetScraperData(c *fiber.Ctx) error {
	requestID := "unknown"
	if id, ok := c.Locals("requestID").(string); ok {
		requestID = id
	}

	// Emplacements possibles du fichier data.json
	possiblePaths := []string{
		"/app/data.json", // R√©pertoire de travail de l'API
		"/go_api_mongo_scrapper/scraper/data.json", // Volume partag√© scraper_data
		"./data.json", // R√©pertoire courant
		"data.json",   // R√©pertoire courant (relatif)
	}

	var filePath string
	var found bool

	// Chercher le fichier dans les emplacements possibles
	for _, path := range possiblePaths {
		if _, err := os.Stat(path); err == nil {
			filePath = path
			found = true
			break
		}
	}

	if !found {
		logger.LogError("Fichier data.json introuvable", nil, map[string]interface{}{
			"request_id":     requestID,
			"searched_paths": possiblePaths,
		})
		return c.Status(404).JSON(fiber.Map{
			"error":   true,
			"message": "Fichier data.json introuvable. Le scraper n'a peut-√™tre pas encore √©t√© ex√©cut√©.",
		})
	}

	// Lire le fichier
	fileContent, err := os.ReadFile(filePath)
	if err != nil {
		logger.LogError("Erreur lors de la lecture du fichier data.json", err, map[string]interface{}{
			"request_id": requestID,
			"file_path":  filePath,
		})
		return c.Status(500).JSON(fiber.Map{
			"error":   true,
			"message": "Erreur lors de la lecture du fichier",
		})
	}

	// Obtenir les informations du fichier
	fileInfo, err := os.Stat(filePath)
	if err != nil {
		logger.LogError("Erreur lors de la r√©cup√©ration des informations du fichier", err, map[string]interface{}{
			"request_id": requestID,
			"file_path":  filePath,
		})
	}

	// D√©finir les headers pour le t√©l√©chargement
	c.Set("Content-Type", "application/json")
	c.Set("Content-Disposition", fmt.Sprintf("attachment; filename=\"scraper-data-%s.json\"", time.Now().Format("20060102-150405")))
	if fileInfo != nil {
		c.Set("Content-Length", fmt.Sprintf("%d", fileInfo.Size()))
	}

	logger.LogInfo("Fichier data.json t√©l√©charg√© avec succ√®s", map[string]interface{}{
		"request_id": requestID,
		"file_path":  filePath,
		"file_size":  len(fileContent),
	})

	// Envoyer le fichier
	return c.Send(fileContent)
}
