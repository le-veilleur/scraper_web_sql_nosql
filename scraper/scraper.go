package main

import (
	"encoding/json"
	"fmt"
	"log"
	"os"
	"runtime"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/gocolly/colly"
)

// Variables de versioning inject√©es lors du build
// Ces valeurs sont remplac√©es par les flags de compilation lors du build Docker
var (
	version   = "dev"     // Version de l'application
	gitCommit = "unknown" // Hash du commit Git
	buildTime = "unknown" // Timestamp de compilation
)

// BuildInfo contient les informations de build pour le debugging et la tra√ßabilit√©
type BuildInfo struct {
	Version   string `json:"version"`    // Version de l'application
	GitCommit string `json:"git_commit"` // Hash du commit Git
	BuildTime string `json:"build_time"` // Timestamp de compilation
	GoVersion string `json:"go_version"` // Version de Go utilis√©e
	OS        string `json:"os"`         // Syst√®me d'exploitation
	Arch      string `json:"arch"`       // Architecture (amd64, arm64, etc.)
}

// Recipe repr√©sente une recette compl√®te avec tous ses d√©tails
type Recipe struct {
	Name         string        `json:"name"`         // Nom de la recette
	Page         string        `json:"page"`         // URL de la page de la recette
	Image        string        `json:"image"`        // URL de l'image de la recette
	Ingredients  []Ingredient  `json:"ingredients"`  // Liste des ingr√©dients
	Instructions []Instruction `json:"instructions"` // Liste des instructions
}

// Ingredient repr√©sente un ingr√©dient avec sa quantit√© et son unit√©
type Ingredient struct {
	Quantity string `json:"quantity"` // Quantit√© (ex: "2", "1/2")
	Unit     string `json:"unit"`     // Unit√© (ex: "cups", "tablespoons")
}

// Instruction repr√©sente une √©tape de la recette
type Instruction struct {
	Number      string `json:"number"`      // Num√©ro de l'√©tape (ex: "1", "2")
	Description string `json:"description"` // Description de l'√©tape
}

// RecipeData contient les informations de base d'une recette avant le scraping d√©taill√©
// Utilis√© pour passer les donn√©es entre les goroutines
type RecipeData struct {
	URL   string // URL de la page de la recette
	Title string // Titre de la recette
	Image string // URL de l'image de la recette
}

// ScrapingStats contient toutes les statistiques de performance du scraper
// Thread-safe gr√¢ce au Mutex pour les acc√®s concurrents
type ScrapingStats struct {
	// Compteurs de requ√™tes HTTP
	TotalRequests    int64 `json:"total_requests"`     // Total des requ√™tes HTTP
	MainPageRequests int64 `json:"main_page_requests"` // Requ√™tes vers les pages de cat√©gories
	RecipeRequests   int64 `json:"recipe_requests"`    // Requ√™tes vers les pages de recettes

	// Compteurs de recettes
	RecipesFound     int64 `json:"recipes_found"`     // Nombre de recettes d√©couvertes
	RecipesCompleted int64 `json:"recipes_completed"` // Nombre de recettes trait√©es avec succ√®s
	RecipesFailed    int64 `json:"recipes_failed"`    // Nombre de recettes en √©chec

	// M√©triques de performance temporelles
	StartTime         time.Time     `json:"start_time"`          // Heure de d√©but du scraping
	EndTime           time.Time     `json:"end_time"`            // Heure de fin du scraping
	TotalDuration     time.Duration `json:"total_duration"`      // Dur√©e totale du scraping
	RequestsPerSecond float64       `json:"requests_per_second"` // Requ√™tes par seconde
	RecipesPerSecond  float64       `json:"recipes_per_second"`  // Recettes par seconde

	// Configuration des workers
	MaxWorkers    int   `json:"max_workers"`    // Nombre maximum de workers
	ActiveWorkers int64 `json:"active_workers"` // Nombre de workers actifs

	// Statistiques d√©taill√©es par worker
	WorkerStats map[int]WorkerStats `json:"worker_stats"` // Map des stats par worker

	Mutex sync.RWMutex // Mutex pour la s√©curit√© des acc√®s concurrents
}

// WorkerStats contient les statistiques d'un worker individuel
type WorkerStats struct {
	WorkerID         int           `json:"worker_id"`         // ID unique du worker
	RequestsHandled  int64         `json:"requests_handled"`  // Nombre de requ√™tes trait√©es
	RecipesProcessed int64         `json:"recipes_processed"` // Nombre de recettes trait√©es
	StartTime        time.Time     `json:"start_time"`        // Heure de d√©marrage du worker
	EndTime          time.Time     `json:"end_time"`          // Heure de fin du worker
	Duration         time.Duration `json:"duration"`          // Dur√©e totale d'activit√©
}

// NewScrapingStats cr√©e une nouvelle instance de ScrapingStats
// maxWorkers: nombre maximum de workers qui seront utilis√©s
func NewScrapingStats(maxWorkers int) *ScrapingStats {
	return &ScrapingStats{
		StartTime:   time.Now(),                // Initialiser avec l'heure actuelle
		MaxWorkers:  maxWorkers,                // Stocker le nombre max de workers
		WorkerStats: make(map[int]WorkerStats), // Initialiser la map des stats par worker
	}
}

// IncrementMainPageRequest incr√©mente le compteur de requ√™tes vers les pages principales
// Thread-safe gr√¢ce au mutex
func (s *ScrapingStats) IncrementMainPageRequest() {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()
	s.TotalRequests++    // Incr√©menter le total des requ√™tes
	s.MainPageRequests++ // Incr√©menter les requ√™tes vers les pages principales
}

// IncrementRecipeRequest incr√©mente le compteur de requ√™tes vers les pages de recettes
// Thread-safe gr√¢ce au mutex
func (s *ScrapingStats) IncrementRecipeRequest() {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()
	s.TotalRequests++  // Incr√©menter le total des requ√™tes
	s.RecipeRequests++ // Incr√©menter les requ√™tes vers les recettes
}

// IncrementRecipesFound incr√©mente le compteur de recettes d√©couvertes
// Thread-safe gr√¢ce au mutex
func (s *ScrapingStats) IncrementRecipesFound() {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()
	s.RecipesFound++ // Incr√©menter le nombre de recettes trouv√©es
}

// IncrementRecipesCompleted incr√©mente le compteur de recettes trait√©es avec succ√®s
// Thread-safe gr√¢ce au mutex
func (s *ScrapingStats) IncrementRecipesCompleted() {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()
	s.RecipesCompleted++ // Incr√©menter le nombre de recettes compl√©t√©es
}

// IncrementRecipesFailed incr√©mente le compteur de recettes en √©chec
// Thread-safe gr√¢ce au mutex
func (s *ScrapingStats) IncrementRecipesFailed() {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()
	s.RecipesFailed++ // Incr√©menter le nombre de recettes √©chou√©es
}

func (s *ScrapingStats) UpdateWorkerStats(workerID int, requests, recipes int64) {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()

	if worker, exists := s.WorkerStats[workerID]; exists {
		worker.RequestsHandled += requests
		worker.RecipesProcessed += recipes
		worker.EndTime = time.Now()
		worker.Duration = worker.EndTime.Sub(worker.StartTime)
		s.WorkerStats[workerID] = worker
	} else {
		s.WorkerStats[workerID] = WorkerStats{
			WorkerID:         workerID,
			RequestsHandled:  requests,
			RecipesProcessed: recipes,
			StartTime:        time.Now(),
			EndTime:          time.Now(),
			Duration:         0,
		}
	}
}

func (s *ScrapingStats) GetTotalRequests() int64 {
	s.Mutex.RLock()
	defer s.Mutex.RUnlock()
	return s.TotalRequests
}

func (s *ScrapingStats) CalculateFinalStats() {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()

	s.EndTime = time.Now()
	s.TotalDuration = s.EndTime.Sub(s.StartTime)

	if s.TotalDuration.Seconds() > 0 {
		s.RequestsPerSecond = float64(s.TotalRequests) / s.TotalDuration.Seconds()
		s.RecipesPerSecond = float64(s.RecipesCompleted) / s.TotalDuration.Seconds()
	}
}

func (s *ScrapingStats) GetDetailedStats() ScrapingStats {
	s.Mutex.RLock()
	defer s.Mutex.RUnlock()

	// Cr√©er une copie sans le mutex
	return ScrapingStats{
		TotalRequests:     s.TotalRequests,
		MainPageRequests:  s.MainPageRequests,
		RecipeRequests:    s.RecipeRequests,
		RecipesFound:      s.RecipesFound,
		RecipesCompleted:  s.RecipesCompleted,
		RecipesFailed:     s.RecipesFailed,
		StartTime:         s.StartTime,
		EndTime:           s.EndTime,
		TotalDuration:     s.TotalDuration,
		RequestsPerSecond: s.RequestsPerSecond,
		RecipesPerSecond:  s.RecipesPerSecond,
		MaxWorkers:        s.MaxWorkers,
		ActiveWorkers:     s.ActiveWorkers,
		WorkerStats:       s.WorkerStats,
	}
}

// getPhysicalCores d√©tecte le vrai nombre de c≈ìurs physiques
func getPhysicalCores() int {
	// M√©thode 1: Lire /proc/cpuinfo sur Linux
	if runtime.GOOS == "linux" {
		if cores := detectPhysicalCoresFromProc(); cores > 0 {
			return cores
		}
	}

	// M√©thode 2: Estimation intelligente bas√©e sur les patterns courants
	numLogicalCPU := runtime.NumCPU()

	// Patterns courants d'hyperthreading
	switch {
	case numLogicalCPU == 1:
		return 1
	case numLogicalCPU == 2:
		return 2 // Probablement 2 c≈ìurs sans HT
	case numLogicalCPU == 4:
		return 2 // Probablement 2 c≈ìurs avec HT
	case numLogicalCPU == 6:
		return 6 // Probablement 6 c≈ìurs sans HT
	case numLogicalCPU == 8:
		return 4 // Probablement 4 c≈ìurs avec HT
	case numLogicalCPU == 12:
		return 6 // Probablement 6 c≈ìurs avec HT
	case numLogicalCPU == 16:
		return 8 // Probablement 8 c≈ìurs avec HT
	case numLogicalCPU == 24:
		return 12 // Probablement 12 c≈ìurs avec HT
	case numLogicalCPU == 32:
		return 16 // Probablement 16 c≈ìurs avec HT
	case numLogicalCPU%2 == 0:
		// Si pair, essayer de diviser par 2 (hyperthreading probable)
		estimated := numLogicalCPU / 2
		if estimated >= 1 {
			return estimated
		}
	}

	// Fallback: utiliser le nombre logique
	return numLogicalCPU
}

// detectPhysicalCoresFromProc lit /proc/cpuinfo pour d√©tecter les vrais c≈ìurs physiques
func detectPhysicalCoresFromProc() int {
	// Cette fonction serait impl√©ment√©e pour lire /proc/cpuinfo
	// et compter les vrais c≈ìurs physiques
	// Pour l'instant, on retourne 0 pour utiliser la m√©thode de fallback
	return 0
}

// calculateAdaptiveRatio calcule le ratio optimal bas√© sur le nombre de c≈ìurs
func calculateAdaptiveRatio(numCores int) int {
	switch {
	case numCores <= 2:
		return 3 // Plus de workers sur machines faibles pour compenser
	case numCores <= 4:
		return 2 // Ratio standard pour machines moyennes
	case numCores <= 8:
		return 2 // Ratio standard pour machines puissantes
	case numCores <= 16:
		return 1 // Moins de workers sur tr√®s grosses machines (√©viter la surcharge)
	default:
		return 1 // Ratio conservateur pour machines extr√™mes
	}
}

// calculateOptimalWorkers calcule le nombre optimal de workers bas√© sur les ressources CPU
// minWorkers: nombre minimum de workers (par d√©faut 1)
// maxWorkers: nombre maximum de workers (par d√©faut 50)
func calculateOptimalWorkers(minWorkers, maxWorkers int) int {
	// D√©tecter le vrai nombre de c≈ìurs physiques
	numPhysicalCores := getPhysicalCores()

	// Calculer le ratio adaptatif bas√© sur le nombre de c≈ìurs
	adaptiveRatio := calculateAdaptiveRatio(numPhysicalCores)

	optimalWorkers := numPhysicalCores * adaptiveRatio

	// Appliquer les limites
	if optimalWorkers < minWorkers {
		optimalWorkers = minWorkers
	}
	if optimalWorkers > maxWorkers {
		optimalWorkers = maxWorkers
	}

	return optimalWorkers
}

// printVersionInfo affiche les informations de version
func printVersionInfo() {
	fmt.Printf("Go MongoDB Scrapper\n")
	fmt.Printf("Version: %s\n", version)
	fmt.Printf("Git Commit: %s\n", gitCommit)
	fmt.Printf("Build Time: %s\n", buildTime)
	fmt.Printf("Go Version: %s\n", runtime.Version())
	fmt.Printf("OS/Arch: %s/%s\n\n", runtime.GOOS, runtime.GOARCH)
}

// getBuildInfo retourne les informations de build
func getBuildInfo() BuildInfo {
	return BuildInfo{
		Version:   version,
		GitCommit: gitCommit,
		BuildTime: buildTime,
		GoVersion: runtime.Version(),
		OS:        runtime.GOOS,
		Arch:      runtime.GOARCH,
	}
}

// createMainCollector cr√©e et configure le collecteur principal pour les pages de cat√©gories
// Ce collecteur visite les pages de listes de recettes et extrait les URLs des recettes individuelles
func createMainCollector(stats *ScrapingStats, recipeURLs chan<- RecipeData) *colly.Collector {
	collector := colly.NewCollector()

	// Configuration des limites pour √™tre respectueux du serveur
	collector.Limit(&colly.LimitRule{
		DomainGlob:  "*",                   // Appliquer √† tous les domaines
		Parallelism: 5,                     // Maximum 5 requ√™tes simultan√©es
		Delay:       50 * time.Millisecond, // D√©lai de 50ms entre les requ√™tes
	})

	// Handler appel√© avant chaque requ√™te HTTP
	collector.OnRequest(func(r *colly.Request) {
		stats.IncrementMainPageRequest() // Incr√©menter le compteur de requ√™tes
		log.Printf("üåê Requ√™te principale vers %s (Total: %d)\n", r.URL, stats.GetTotalRequests())
	})

	// Handler appel√© pour chaque √©l√©ment HTML correspondant au s√©lecteur CSS
	// Ce s√©lecteur cible les cartes de recettes sur AllRecipes
	collector.OnHTML("div.mntl-taxonomysc-article-list-group .mntl-card", func(e *colly.HTMLElement) {
		// Extraire l'URL, le titre et l'image de la recette
		page := e.Request.AbsoluteURL(e.Attr("href")) // URL de la page de la recette
		title := e.ChildText("span.card__title-text") // Titre de la recette
		image := e.ChildAttr("img", "data-src")       // URL de l'image

		// V√©rifier que nous avons les donn√©es essentielles
		if page != "" && title != "" {
			stats.IncrementRecipesFound() // Incr√©menter le compteur de recettes trouv√©es

			// Cr√©er l'objet RecipeData avec les informations extraites
			recipeData := RecipeData{
				URL:   page,
				Title: title,
				Image: image,
			}

			// Envoyer la recette dans le channel (non-bloquant)
			select {
			case recipeURLs <- recipeData:
				log.Printf("üìù Recette #%d ajout√©e √† la queue: '%s'\n", stats.RecipesFound, title)
			default:
				log.Printf("‚ö†Ô∏è  Channel plein, recette ignor√©e: '%s'\n", title)
			}
		}
	})

	return collector
}

// createMainCollectorWithPagination cr√©e un collecteur avec support de la pagination
func createMainCollectorWithPagination(stats *ScrapingStats, recipeURLs chan<- RecipeData, maxPages int) *colly.Collector {
	collector := colly.NewCollector()
	collector.Limit(&colly.LimitRule{
		DomainGlob:  "*",
		Parallelism: 10,                     // R√©duit pour √©viter de surcharger le serveur
		Delay:       100 * time.Millisecond, // D√©lai augment√© pour √™tre plus respectueux
	})

	// Map pour suivre les pages visit√©es par cat√©gorie
	visitedPages := make(map[string]int)
	var mutex sync.Mutex

	collector.OnRequest(func(r *colly.Request) {
		stats.IncrementMainPageRequest()
		log.Printf("üåê Requ√™te principale vers %s (Total: %d)\n", r.URL, stats.GetTotalRequests())
	})

	// G√©rer les recettes sur la page actuelle
	collector.OnHTML("div.mntl-taxonomysc-article-list-group .mntl-card", func(e *colly.HTMLElement) {
		page := e.Request.AbsoluteURL(e.Attr("href"))
		title := e.ChildText("span.card__title-text")
		image := e.ChildAttr("img", "data-src")

		if page != "" && title != "" {
			stats.IncrementRecipesFound()
			recipeData := RecipeData{
				URL:   page,
				Title: title,
				Image: image,
			}

			select {
			case recipeURLs <- recipeData:
				log.Printf("üìù Recette #%d ajout√©e √† la queue: '%s'\n", stats.RecipesFound, title)
			default:
				log.Printf("‚ö†Ô∏è  Channel plein, recette ignor√©e: '%s'\n", title)
			}
		}
	})

	// G√©rer la pagination
	collector.OnHTML("a[data-testid='pagination-next']", func(e *colly.HTMLElement) {
		nextPageURL := e.Request.AbsoluteURL(e.Attr("href"))
		if nextPageURL == "" {
			return
		}

		// Extraire la cat√©gorie de base de l'URL actuelle
		baseCategory := e.Request.URL.Path
		if strings.Contains(baseCategory, "?") {
			baseCategory = strings.Split(baseCategory, "?")[0]
		}

		mutex.Lock()
		pagesVisited := visitedPages[baseCategory]
		mutex.Unlock()

		if pagesVisited < maxPages {
			mutex.Lock()
			visitedPages[baseCategory] = pagesVisited + 1
			mutex.Unlock()

			log.Printf("üìÑ Page suivante trouv√©e pour %s (page %d/%d): %s\n", baseCategory, pagesVisited+1, maxPages, nextPageURL)

			// Visiter la page suivante avec un d√©lai
			time.Sleep(500 * time.Millisecond)
			collector.Visit(nextPageURL)
		} else {
			log.Printf("‚úÖ Limite de pages atteinte pour %s (%d pages)\n", baseCategory, maxPages)
		}
	})

	return collector
}

// createRecipeCollector cr√©e un collecteur pour scraper une recette individuelle
func createRecipeCollector(stats *ScrapingStats) *colly.Collector {
	collector := colly.NewCollector()
	collector.Limit(&colly.LimitRule{
		DomainGlob:  "*",
		Parallelism: 1,
		Delay:       50 * time.Millisecond,
	})

	collector.OnRequest(func(r *colly.Request) {
		stats.IncrementRecipeRequest()
		log.Printf("üîç Requ√™te recette vers %s (Total: %d)\n", r.URL, stats.GetTotalRequests())
	})

	return collector
}

// scrapeRecipeDetails configure les handlers pour extraire les d√©tails d'une recette
func scrapeRecipeDetails(collector *colly.Collector, recipe *Recipe, completedRecipes chan<- Recipe, stats *ScrapingStats) {
	// Collecter les ingr√©dients - Nouveaux s√©lecteurs CSS pour AllRecipes 2024
	collector.OnHTML("ul.mm-recipes-structured-ingredients__list", func(e *colly.HTMLElement) {
		var ingredients []Ingredient

		e.ForEach("li.mm-recipes-structured-ingredients__list-item", func(_ int, ingr *colly.HTMLElement) {
			// Extraire la quantit√© et l'unit√© s√©par√©ment
			quantity := strings.TrimSpace(ingr.ChildText("span[data-ingredient-quantity=true]"))
			unit := strings.TrimSpace(ingr.ChildText("span[data-ingredient-unit=true]"))
			name := strings.TrimSpace(ingr.ChildText("span[data-ingredient-name=true]"))

			// Si on a des donn√©es structur√©es, les utiliser
			if quantity != "" || unit != "" || name != "" {
				// Construire le texte complet de l'ingr√©dient
				fullText := strings.TrimSpace(ingr.Text)
				ingredients = append(ingredients, Ingredient{
					Quantity: fullText, // Texte complet pour l'instant
					Unit:     "",       // Pas de s√©paration pour l'instant
				})
			}
		})

		recipe.Ingredients = ingredients
		log.Printf("üîç Ingr√©dients trouv√©s: %d pour '%s'\n", len(ingredients), recipe.Name)
	})

	// Collecter les instructions - Nouveaux s√©lecteurs CSS pour AllRecipes 2024
	collector.OnHTML("div.mm-recipes-steps__content", func(e *colly.HTMLElement) {
		var instructions []Instruction

		// Chercher dans les listes ordonn√©es avec la structure correcte
		e.ForEach("ol.mntl-sc-block li", func(i int, inst *colly.HTMLElement) {
			number := strconv.Itoa(i + 1)
			// Extraire le texte de la balise <p> √† l'int√©rieur du <li>
			description := strings.TrimSpace(inst.ChildText("p.mntl-sc-block-html"))
			if description == "" {
				// Fallback sur le texte complet si pas de balise p
				description = strings.TrimSpace(inst.Text)
			}
			if description != "" {
				instructions = append(instructions, Instruction{
					Number:      number,
					Description: description,
				})
			}
		})

		recipe.Instructions = instructions
		log.Printf("üîç Instructions trouv√©es: %d pour '%s'\n", len(instructions), recipe.Name)
	})

	// Quand le scraping de la recette est termin√©
	collector.OnScraped(func(r *colly.Response) {
		stats.IncrementRecipesCompleted()
		completedRecipes <- *recipe
		log.Printf("‚úÖ Recette #%d compl√©t√©e: '%s'\n", stats.RecipesCompleted, recipe.Name)
	})
}

// processRecipeReusable traite une recette dans un worker r√©utilisable
func processRecipeReusable(recipeData RecipeData, stats *ScrapingStats, completedRecipes chan<- Recipe, workerStats *WorkerStats) {
	startTime := time.Now()
	log.Printf("üöÄ Worker #%d traite la recette: %s\n", workerStats.WorkerID, recipeData.Title)

	// Cr√©er un collecteur d√©di√© pour cette recette
	recipeCollector := createRecipeCollector(stats)

	recipe := Recipe{
		Name:  recipeData.Title,
		Page:  recipeData.URL,
		Image: recipeData.Image,
	}

	// Configurer le scraping des d√©tails
	scrapeRecipeDetails(recipeCollector, &recipe, completedRecipes, stats)

	// Visiter la page de la recette
	err := recipeCollector.Visit(recipeData.URL)
	if err != nil {
		stats.IncrementRecipesFailed()
		log.Printf("‚ùå Worker #%d - Erreur lors de la visite de la page de recette '%s': %v\n", workerStats.WorkerID, recipeData.Title, err)
	} else {
		// Mettre √† jour les stats du worker
		workerStats.RequestsHandled++
		workerStats.RecipesProcessed++
	}

	duration := time.Since(startTime)
	log.Printf("‚è±Ô∏è  Worker #%d termin√© en %v: %s\n", workerStats.WorkerID, duration, recipeData.Title)
}

// startRecipeProcessor d√©marre la goroutine qui traite les URLs de recettes
func startRecipeProcessor(recipeURLs <-chan RecipeData, completedRecipes chan<- Recipe, stats *ScrapingStats, wg *sync.WaitGroup) {
	go func() {
		maxWorkers := stats.MaxWorkers // Utiliser le nombre optimal calcul√© automatiquement
		semaphore := make(chan struct{}, maxWorkers)

		log.Printf("üè≠ Initialisation de %d workers pour le traitement des recettes\n", maxWorkers)

		// Cr√©er des workers r√©utilisables
		for i := 0; i < maxWorkers; i++ {
			wg.Add(1)
			go func(workerID int) {
				defer wg.Done()
				workerStats := WorkerStats{
					WorkerID:         workerID,
					RequestsHandled:  0,
					RecipesProcessed: 0,
					StartTime:        time.Now(),
				}

				log.Printf("üöÄ Worker #%d d√©marr√©\n", workerID)

				// Le worker traite les recettes en continu
				for recipeData := range recipeURLs {
					// Acqu√©rir un slot dans le semaphore
					semaphore <- struct{}{}

					// Traiter la recette
					processRecipeReusable(recipeData, stats, completedRecipes, &workerStats)

					// Lib√©rer le slot
					<-semaphore
				}

				// Mettre √† jour les stats finales du worker
				workerStats.EndTime = time.Now()
				workerStats.Duration = workerStats.EndTime.Sub(workerStats.StartTime)
				stats.Mutex.Lock()
				stats.WorkerStats[workerID] = workerStats
				stats.Mutex.Unlock()

				log.Printf("üèÅ Worker #%d termin√©: %d requ√™tes, %d recettes, %v\n",
					workerID, workerStats.RequestsHandled, workerStats.RecipesProcessed, workerStats.Duration)
			}(i)
		}

		log.Printf("üìä %d workers r√©utilisables d√©marr√©s et pr√™ts √† traiter les recettes\n", maxWorkers)

		// Attendre que toutes les goroutines se terminent
		wg.Wait()
		close(completedRecipes)
		log.Printf("üèÅ Tous les %d workers ont termin√©\n", maxWorkers)
	}()
}

// startRecipeCollector d√©marre la goroutine qui collecte les recettes termin√©es
func startRecipeCollector(completedRecipes <-chan Recipe, recipes *[]Recipe, recipesMutex *sync.RWMutex, done chan<- bool) {
	go func() {
		for recipe := range completedRecipes {
			recipesMutex.Lock()
			*recipes = append(*recipes, recipe)
			recipesMutex.Unlock()
		}
		done <- true
	}()
}

// saveRecipesToFile sauvegarde les recettes dans un fichier JSON
func saveRecipesToFile(recipes []Recipe, filename string) error {
	content, err := json.MarshalIndent(recipes, "", "  ")
	if err != nil {
		return err
	}

	return os.WriteFile(filename, content, 0644)
}

// printDetailedStats affiche les statistiques d√©taill√©es
func printDetailedStats(stats *ScrapingStats, filename string) {
	stats.CalculateFinalStats()
	detailedStats := stats.GetDetailedStats()

	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("üìä STATISTIQUES D√âTAILL√âES DU SCRAPER")
	fmt.Println(strings.Repeat("=", 80))

	// Performance g√©n√©rale
	fmt.Printf("‚è±Ô∏è  Dur√©e totale: %v\n", detailedStats.TotalDuration)
	fmt.Printf("üöÄ Requ√™tes par seconde: %.2f\n", detailedStats.RequestsPerSecond)
	fmt.Printf("üìù Recettes par seconde: %.2f\n", detailedStats.RecipesPerSecond)

	// Requ√™tes
	fmt.Println("\nüåê REQU√äTES:")
	fmt.Printf("   Total: %d\n", detailedStats.TotalRequests)
	fmt.Printf("   Page principale: %d\n", detailedStats.MainPageRequests)
	fmt.Printf("   Pages recettes: %d\n", detailedStats.RecipeRequests)

	// Recettes
	fmt.Println("\nüìù RECETTES:")
	fmt.Printf("   Trouv√©es: %d\n", detailedStats.RecipesFound)
	fmt.Printf("   Compl√©t√©es: %d\n", detailedStats.RecipesCompleted)
	fmt.Printf("   √âchou√©es: %d\n", detailedStats.RecipesFailed)
	fmt.Printf("   Taux de succ√®s: %.1f%%\n", float64(detailedStats.RecipesCompleted)/float64(detailedStats.RecipesFound)*100)

	// Configuration automatique
	numLogicalCPU := runtime.NumCPU()
	numPhysicalCores := getPhysicalCores()
	adaptiveRatio := calculateAdaptiveRatio(numPhysicalCores)
	fmt.Println("\nüíª CONFIGURATION AUTOMATIQUE:")
	fmt.Printf("   Processeurs logiques: %d\n", numLogicalCPU)
	fmt.Printf("   C≈ìurs physiques d√©tect√©s: %d\n", numPhysicalCores)
	fmt.Printf("   Ratio adaptatif: %d (calcul√© automatiquement)\n", adaptiveRatio)
	fmt.Printf("   Calcul: %d c≈ìurs √ó %d = %d workers\n", numPhysicalCores, adaptiveRatio, numPhysicalCores*adaptiveRatio)
	fmt.Printf("   Configuration finale: %d workers\n", detailedStats.MaxWorkers)

	// D√©tails par worker
	if len(detailedStats.WorkerStats) > 0 {
		fmt.Println("\nüìà PERFORMANCE PAR WORKER:")
		for workerID, workerStats := range detailedStats.WorkerStats {
			fmt.Printf("   Worker #%d: %d requ√™tes, %d recettes, %v\n",
				workerID, workerStats.RequestsHandled, workerStats.RecipesProcessed, workerStats.Duration)
		}
	}

	// Calculs de performance
	avgRequestsPerRecipe := float64(detailedStats.RecipeRequests) / float64(detailedStats.RecipesCompleted)
	fmt.Println("\nüí° ANALYSE DE PERFORMANCE:")
	fmt.Printf("   Requ√™tes moyennes par recette: %.1f\n", avgRequestsPerRecipe)
	fmt.Printf("   D√©bit estim√©: %.0f requ√™tes/seconde\n", detailedStats.RequestsPerSecond)

	if detailedStats.RecipesPerSecond > 0 {
		fmt.Printf("   Temps moyen par recette: %.2f secondes\n", 1/detailedStats.RecipesPerSecond)
	}

	fmt.Printf("\nüíæ Fichier de sortie: %s\n", filename)
	fmt.Println(strings.Repeat("=", 80))
}

// printRealTimeStats affiche les statistiques en temps r√©el
func printRealTimeStats(stats *ScrapingStats) {
	ticker := time.NewTicker(5 * time.Second)
	go func() {
		for range ticker.C {
			stats.Mutex.RLock()
			elapsed := time.Since(stats.StartTime)
			requestsPerSec := float64(stats.TotalRequests) / elapsed.Seconds()
			recipesPerSec := float64(stats.RecipesCompleted) / elapsed.Seconds()
			stats.Mutex.RUnlock()

			fmt.Printf("üìä [%v] Req: %d (%.1f/s) | Recettes: %d/%d (%.1f/s) | Workers: %d\n",
				elapsed.Round(time.Second), stats.TotalRequests, requestsPerSec,
				stats.RecipesCompleted, stats.RecipesFound, recipesPerSec, len(stats.WorkerStats))
		}
	}()
}

// main est la fonction principale du scraper
// Elle orchestre tout le processus de scraping : collecte des URLs, traitement des recettes, et sauvegarde
func main() {
	// ===== PHASE 1: INITIALISATION =====
	// Afficher les informations de version et de build
	printVersionInfo()

	// Configuration du scraper - param√®tres ajustables
	const minWorkers = 1          // Nombre minimum de workers
	const maxWorkers = 100        // Nombre maximum de workers
	const maxPagesPerCategory = 5 // Nombre maximum de pages √† scraper par cat√©gorie
	const maxRecipesPerPage = 20  // Estimation du nombre de recettes par page

	// Configuration automatique bas√©e sur les ressources CPU
	optimalWorkers := calculateOptimalWorkers(minWorkers, maxWorkers)

	// Afficher la configuration automatique d√©taill√©e
	numLogicalCPU := runtime.NumCPU()
	numPhysicalCores := getPhysicalCores()
	adaptiveRatio := calculateAdaptiveRatio(numPhysicalCores)
	calculatedWorkers := numPhysicalCores * adaptiveRatio
	log.Printf("üîç D√âTECTION AUTOMATIQUE DES RESSOURCES:")
	log.Printf("   üíª Processeurs logiques: %d", numLogicalCPU)
	log.Printf("   üîß C≈ìurs physiques d√©tect√©s: %d", numPhysicalCores)
	log.Printf("   ‚öôÔ∏è  Ratio adaptatif: %d (calcul√© automatiquement)", adaptiveRatio)
	log.Printf("   üßÆ Calcul: %d c≈ìurs √ó %d = %d workers", numPhysicalCores, adaptiveRatio, calculatedWorkers)
	if calculatedWorkers < minWorkers {
		log.Printf("   ‚ö†Ô∏è  Limite minimum appliqu√©e: %d ‚Üí %d workers", calculatedWorkers, minWorkers)
	} else if calculatedWorkers > maxWorkers {
		log.Printf("   ‚ö†Ô∏è  Limite maximum appliqu√©e: %d ‚Üí %d workers", calculatedWorkers, maxWorkers)
	} else {
		log.Printf("   ‚úÖ Configuration optimale: %d workers", optimalWorkers)
	}

	// Cr√©er l'objet de statistiques thread-safe
	stats := NewScrapingStats(optimalWorkers)

	// Afficher les informations de d√©marrage
	log.Printf("üöÄ D√©marrage du script de scraping avec %d goroutines (version %s)...\n", optimalWorkers, version)
	log.Printf("üìã Build info: %+v\n", getBuildInfo())
	log.Printf("üìä Configuration: %d pages/cat√©gorie, %d recettes/page max\n", maxPagesPerCategory, maxRecipesPerPage)

	// D√©marrer l'affichage des statistiques en temps r√©el (goroutine s√©par√©e)
	printRealTimeStats(stats)

	// ===== PHASE 2: CONFIGURATION DES CHANNELS =====
	// Channels pour la communication entre goroutines (pipeline de donn√©es)
	recipeURLs := make(chan RecipeData, 2000)   // Channel pour les URLs de recettes (buffer de 2000)
	completedRecipes := make(chan Recipe, 2000) // Channel pour les recettes compl√©t√©es (buffer de 2000)
	done := make(chan bool)                     // Channel de signalisation de fin

	// Slice thread-safe pour stocker toutes les recettes finales
	var recipes []Recipe
	var recipesMutex sync.RWMutex // Mutex pour prot√©ger l'acc√®s concurrent au slice

	// WaitGroup pour synchroniser l'attente de la fin de toutes les goroutines
	var wg sync.WaitGroup

	// ===== PHASE 3: CONFIGURATION DES COLLECTEURS =====
	// Cr√©er le collecteur principal avec support de la pagination
	mainCollector := createMainCollectorWithPagination(stats, recipeURLs, maxPagesPerCategory)

	// ===== PHASE 4: D√âMARRAGE DES GOROUTINES DE TRAITEMENT =====
	// D√©marrer la goroutine qui collecte les recettes termin√©es
	startRecipeCollector(completedRecipes, &recipes, &recipesMutex, done)

	// D√©marrer les workers qui traitent les URLs de recettes
	startRecipeProcessor(recipeURLs, completedRecipes, stats, &wg)

	// ===== PHASE 5: D√âFINITION DES CAT√âGORIES √Ä SCRAPER =====
	// Liste des cat√©gories de recettes AllRecipes √† scraper
	// Chaque cat√©gorie sera visit√©e avec pagination automatique
	categories := []string{
		"https://www.allrecipes.com/recipes/16369/soups-stews-and-chili/soup/",               // Soupes
		"https://www.allrecipes.com/recipes/1246/soups-stews-and-chili/soup/chicken-soup/",   // Soupes de poulet
		"https://www.allrecipes.com/recipes/76/appetizers-and-snacks/",                       // Ap√©ritifs et collations
		"https://www.allrecipes.com/recipes/113/appetizers-and-snacks/pastries/",             // P√¢tisseries
		"https://www.allrecipes.com/recipes/1059/fruits-and-vegetables/vegetables/",          // L√©gumes
		"https://www.allrecipes.com/recipes/1083/fruits-and-vegetables/vegetables/cucumber/", // Concombres
		"https://www.allrecipes.com/recipes/77/drinks/",                                      // Boissons
		"https://www.allrecipes.com/recipes/79/desserts/",                                    // Desserts
		"https://www.allrecipes.com/recipes/81/side-dish/",                                   // Accompagnements
		"https://www.allrecipes.com/recipes/1569/everyday-cooking/on-the-go/tailgating/",     // Tailgating
	}

	// ===== PHASE 6: EX√âCUTION DU SCRAPING =====
	// D√©marrer le scraping de toutes les cat√©gories d√©finies
	log.Printf("D√©but du scraping de %d cat√©gories...\n", len(categories))
	for i, category := range categories {
		log.Printf("üåê Scraping cat√©gorie %d/%d: %s\n", i+1, len(categories), category)

		// Visiter la cat√©gorie (avec pagination automatique)
		err := mainCollector.Visit(category)
		if err != nil {
			log.Printf("‚ö†Ô∏è  Erreur lors de la visite de la cat√©gorie %s: %v\n", category, err)
			continue // Continuer avec la cat√©gorie suivante en cas d'erreur
		}

		// Pause respectueuse entre les cat√©gories pour √©viter de surcharger le serveur
		time.Sleep(1 * time.Second)
	}

	// ===== PHASE 7: FINALISATION =====
	// Fermer le channel des URLs pour signaler qu'il n'y a plus de recettes √† traiter
	close(recipeURLs)

	// Attendre que toutes les recettes soient collect√©es (signal du collector)
	<-done

	// ===== PHASE 8: SAUVEGARDE ET STATISTIQUES =====
	// Sauvegarder toutes les recettes dans un fichier JSON
	filename := "data.json"
	recipesMutex.RLock()
	err := saveRecipesToFile(recipes, filename)
	recipesMutex.RUnlock()

	if err != nil {
		log.Printf("Erreur lors de l'enregistrement des recettes: %v\n", err)
		return
	}

	// Afficher les statistiques d√©taill√©es de performance
	printDetailedStats(stats, filename)

	// Afficher les informations de build dans les logs finaux
	log.Printf("Scraping termin√© avec la version %s (commit: %s)\n", version, gitCommit)
}
